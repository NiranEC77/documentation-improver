# LLM deployment temporarily disabled due to resource constraints and PVC issues
# 
# To enable LLM service:
# 1. Ensure your cluster has sufficient resources (1Gi+ memory, 500m+ CPU)
# 2. Verify storage class "standard" exists: kubectl get storageclass
# 3. Use k8s/llm-deployment-optional.yaml instead
#
# This file is kept for reference but commented out to prevent scheduling failures

# apiVersion: v1
# kind: Namespace
# metadata:
#   name: doc-improver
# ---
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: documentation-improver-llm
#   namespace: doc-improver
#   labels:
#     app: documentation-improver-llm
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: documentation-improver-llm
#   template:
#     metadata:
#       labels:
#         app: documentation-improver-llm
#     spec:
#       securityContext:
#         runAsNonRoot: true
#         runAsUser: 1000
#         runAsGroup: 1000
#         fsGroup: 1000
#         seccompProfile:
#           type: RuntimeDefault
#       containers:
#         - name: llm
#           image: ollama/ollama:latest
#           ports:
#             - containerPort: 11434
#           env:
#             - name: OLLAMA_HOST
#               value: "0.0.0.0"
#             - name: OLLAMA_ORIGINS
#               value: "*"
#           resources:
#             requests:
#               memory: "1Gi"
#               cpu: "500m"
#             limits:
#               memory: "2Gi"
#               cpu: "1"
#           livenessProbe:
#             httpGet:
#               path: /api/tags
#               port: 11434
#             initialDelaySeconds: 60
#             periodSeconds: 30
#           readinessProbe:
#             httpGet:
#               path: /api/tags
#               port: 11434
#             initialDelaySeconds: 30
#             periodSeconds: 10
#           volumeMounts:
#             - name: ollama-data
#               mountPath: /root/.ollama
#             - name: models
#               mountPath: /models
#       volumes:
#         - name: ollama-data
#           persistentVolumeClaim:
#             claimName: ollama-pvc
#         - name: models
#           persistentVolumeClaim:
#             claimName: models-pvc
# ---
# apiVersion: v1
# kind: Service
# metadata:
#   name: documentation-improver-llm-service
#   namespace: doc-improver
#   labels:
#     app: documentation-improver-llm
# spec:
#   selector:
#     app: documentation-improver-llm
#   ports:
#     - protocol: TCP
#       port: 11434
#       targetPort: 11434
#   type: ClusterIP
# ---
# apiVersion: v1
# kind: PersistentVolumeClaim
# metadata:
#   name: ollama-pvc
#   namespace: doc-improver
# spec:
#   storageClassName: "standard"  # Use default storage class
#   accessModes:
#     - ReadWriteOnce
#   resources:
#     requests:
#       storage: 5Gi  # Reduced storage size
# ---
# apiVersion: v1
# kind: PersistentVolumeClaim
# metadata:
#   name: models-pvc
#   namespace: doc-improver
# spec:
#   storageClassName: "standard"  # Use default storage class
#   accessModes:
#     - ReadWriteOnce
#   resources:
#     requests:
#       storage: 10Gi  # Reduced storage size